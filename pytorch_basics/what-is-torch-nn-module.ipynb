{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "04cf257d0d697206bc3fd9ea9972d00920bfe789"
   },
   "source": [
    "## WHAT IS TORCH.NN REALLY?\n",
    "\n",
    "Pytorch provides elegantly designed modules and classes like torch.nn, torch.optim, Dataset and Dataloader which makes creating and training neural networks much simpler. In order to fully utilize thier potential and customize them as per your requirements we need to understand what each piece actually does. We will start out by creating our models from scratch using only pytorch's basic tensor functionality. Then incrementally moodify our code by adding features from torch.nn, torch.optim, Dataset and Dataloader one by one, showing exactly what each piece does. This will make our code more flexible and concise.\n",
    "\n",
    "We will use MNIST as our dataset, which consists of greyscale images of handwritten digits. The images have a resolution of 28 x 28. We will make use of pathlib to deal with paths and download our dataset using requests module. We will import packages only when required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "WORK_DIR = Path('D:/work/workspace/machine_learning/Datasets')\n",
    "DATA_PATH = WORK_DIR / 'MNIST'\n",
    "\n",
    "# create data directory\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "URL = \"http://deeplearning.net/data/mnist/\"\n",
    "FILENAME = \"mnist.pkl.gz\"\n",
    "\n",
    "# check if file is already downloaded or not \n",
    "if not (DATA_PATH / FILENAME).exists():\n",
    "    content = requests.get(URL + FILENAME).content\n",
    "    (DATA_PATH/FILENAME).open('wb').write(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Write constant variables with caps\n",
    "\n",
    "Here the data exists in the form of numpy arrays, and has been saved using pickle, a python specific-format for serializing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip # the data is zipped\n",
    "import pickle # to load the pickle data\n",
    "\n",
    "# as_posix give the str representation of path\n",
    "with gzip.open((DATA_PATH/FILENAME).as_posix(), 'rb') as f:\n",
    "    ((x_train, y_train), (x_val, y_val), _) = pickle.load(f, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "# check if data loaded properly \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# reshape the images, currenlty flattened to 784 (28 x 28)\n",
    "plt.imshow(x_train[0].reshape(28, 28), cmap='Greys_r')\n",
    "plt.show()\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "dd4fd81949f9203311690d7a6c5c194935f6c1cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 784])\n",
      "torch.Size([10000, 784])\n"
     ]
    }
   ],
   "source": [
    "# convert data to tensors\n",
    "import torch\n",
    "\n",
    "# torch.tensor(np.array) assigns the dtype automatically\n",
    "x_train, y_train, x_val, y_val = map(torch.tensor, (x_train, y_train, x_val, y_val))\n",
    "n, c = x_train.shape\n",
    "print(x_train.shape)\n",
    "print(x_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e3fd6a211a9e2634539382bd62032f5daa752d96"
   },
   "source": [
    "## Neural net from scratch (no torch.nn)\n",
    "\n",
    "requires_grad: tells torch to record all operations perfomed on that tensor, so we can get the gradients during back-prop automatically For the weights we specify requires_grad=True after initialization, beacuse we don't want that step included for back-prop.\n",
    "\n",
    "For the weight initialization we use Xavier Initialization (multiply the weights by 1/sqrt(n)), where n #of input units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "weights = torch.randn(784, 10) / math.sqrt(784)\n",
    "weights.requires_grad_() # in_place, don't want initialization step to be accounted for back_prop\n",
    "bias = torch.zeros(10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Pytorch provides the functionality that calculated gradients automatically we can use any function or callable object as our model. Although pytorch has a lot of pre-defined activation and loss functions, we can easily create our own using python functions. Torch will automatically create fast GPU or vectorized CPU code for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(xb):\n",
    "    return log_softmax(xb @ weights + bias)\n",
    "\n",
    "def log_softmax(x):\n",
    "    return x - x.exp().sum(-1).log().unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above, the @ stands for the dot product operation. We will call our function on one batch of data (in this case, 64 images). This is one forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs = 64\n",
    "\n",
    "xb = x_train[0:bs]\n",
    "preds = model(xb) \n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s implement negative log-likelihood to use as the loss function (again, we can just use standard Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll(input, target):\n",
    "    return -input[range(target.shape[0]), target].mean()\n",
    "\n",
    "loss_func = nll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check our loss with our random model, so we can see if we improve after a backprop pass later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3587, grad_fn=<NegBackward>)\n"
     ]
    }
   ],
   "source": [
    "yb = y_train[0:bs]\n",
    "print(loss_func(preds, yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s also implement a function to calculate the accuracy of our model. For each prediction, if the index with the largest value matches the target value, then the prediction was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    preds = torch.argmax(out, dim=1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the accuracy of our random model, so we can see if our accuracy improves as our loss improves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0469)\n"
     ]
    }
   ],
   "source": [
    "print(accuracy(preds, yb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.03\n",
    "epochs= 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range((n - 1) // bs + 1):\n",
    "        start_i = i*bs\n",
    "        end_i = start_i + bs\n",
    "        xb = x_train[start_i:end_i]\n",
    "        yb = y_train[start_i:end_i]\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "        loss.backward()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            weights -= weights.grad * lr\n",
    "            bias -= bias.grad * lr\n",
    "            weights.grad.zero_()\n",
    "            bias.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s check the loss and accuracy and compare those to what we got earlier. We expect that the loss will have decreased and accuracy to have increased, and they have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7467, grad_fn=<NegBackward>) tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using torch.nn.functional\n",
    "We will now refactor our code, so that it does the same thing as before, only we’ll start taking advantage of PyTorch’s nn classes to make it more concise and flexible. At each step from here, we should be making our code one or more of: shorter, more understandable, and/or more flexible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "loss_func = F.cross_entropy\n",
    "\n",
    "def model(xb):\n",
    "    return xb @ weights + bias  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we no longer call log_softmax in the model function. Let’s confirm that our loss and accuracy are the same as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7467, grad_fn=<NllLossBackward>) tensor(0.8750)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb), accuracy(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using nn.Module\n",
    "Next up, we’ll use nn.Module and nn.Parameter, for a clearer and more concise training loop. We subclass nn.Module (which itself is a class and able to keep track of state). In this case, we want to create a class that holds our weights, bias, and method for the forward step. nn.Module has a number of attributes and methods (such as .parameters() and .zero_grad()) which we will be using.\n",
    "\n",
    "nn.Parameter(): wraps around a tensor requiring auto_grad to make it a model parameter to be updated\n",
    "nn.Module: inheriting into a class makes the class keep track of weights, layers and the forward step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class Mnist_Logistic(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(784, 10))\n",
    "        self.bias = nn.Parameter(torch.zeros(10))\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return xb @ self.weight + self.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we’re now using an object instead of just using a function, we first have to instantiate our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Mnist_Logistic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the loss in the same way as before. Note that nn.Module objects are used as if they are functions (i.e they are callable), but behind the scenes Pytorch will call our forward method automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.4556, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take advantage of model.parameters() and model.zero_grad() (which are both defined by PyTorch for nn.Module) to make those steps more concise and less prone to the error of forgetting some of our parameters, particularly if we had a more complicated model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`with torch.no_grad():\n",
    "    for p in model.parameters():\n",
    "        p -= p.grad * lr\n",
    "        model.zero_grad()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ll wrap our little training loop in a fit function so we can run it again later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for p in model.parameters():\n",
    "                    p -= p.grad * lr\n",
    "                    model.zero_grad()\n",
    "                    \n",
    "fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s double-check that our loss has gone down:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.9430, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using nn.Linear\n",
    "We continue to refactor our code. Instead of manually defining and initializing self.weights and self.bias, and calculating xb  @ self.weights + self.bias, we will instead use the Pytorch class nn.Linear for a linear layer, which does all that for us. Pytorch has many types of predefined layers that can greatly simplify our code, and often makes it faster too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_Logistic(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(784, 10)\n",
    "        \n",
    "    def forward(self, xb):\n",
    "        return self.fc(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We instantiate our model and calculate the loss in the same way as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.2830, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_Logistic()\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor using optim\n",
    "Pytorch also has a package with various optimization algorithms, torch.optim. We can use the step method from our optimizer to take a forward step, instead of manually updating each parameter.\n",
    "\n",
    "This will let us replace our previous manually coded optimization step:\n",
    "\n",
    "`with torch.no_grad():\n",
    "    for p in model.parameters(): p -= p.grad * lr\n",
    "    model.zero_grad()`\n",
    "    \n",
    "**Note:** optimizer.step() and optimizer.zero_grad() will do these but doesn't require torch.no_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1) // bs + 1):\n",
    "            start_i = i * bs\n",
    "            end_i = start_i + bs\n",
    "            xb = x_train[start_i:end_i]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "                    \n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7430, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using Dataset\n",
    "PyTorch has an abstract Dataset class. A Dataset can be anything that has a __len__ function (called by Python’s standard len function) and a __getitem__ function as a way of indexing into it (so we can access the first dimension).\n",
    "\n",
    "PyTorch’s TensorDataset is a Dataset wrapping tensors. By defining a length and way of indexing, this also gives us a way to iterate, index, and slice along the first dimension of a tensor. This will make it easier to access both the independent and dependent variables in the same line as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both x_train and y_train can be combined in a single TensorDataset, which will be easier to iterate over and slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Mnist_Logistic()\n",
    "    opt = optim.SGD(model.parameters(), lr=lr)\n",
    "    return model, opt\n",
    "\n",
    "model, opt = get_model()\n",
    "\n",
    "def fit():\n",
    "    for epoch in range(epochs):\n",
    "        for i in range((n-1) // bs + 1):\n",
    "            xb, yb = train_ds[i*bs: i*bs+bs] # gives back tuple\n",
    "            preds = model(xb)\n",
    "            loss = loss_func(preds, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "                    \n",
    "fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7453, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Refactor using DataLoader\n",
    "Pytorch’s DataLoader is responsible for managing batches. You can create a DataLoader from any Dataset. DataLoader makes it easier to iterate over batches. Rather than having to use `train_ds[i*bs : i*bs+bs]`, the DataLoader gives us each minibatch automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7413, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "print(loss_func(model(xb), yb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to Pytorch’s nn.Module, nn.Parameter, Dataset, and DataLoader, our training loop is now dramatically smaller and easier to understand. Let’s now try to add the basic features necessary to create effecive models in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add validation\n",
    "In section 1, we were just trying to get a reasonable training loop set up for use on our training data. In reality, you always should also have a validation set, in order to identify if you are overfitting.\n",
    "\n",
    "Shuffling the training data is important to prevent correlation between batches and overfitting. On the other hand, the validation loss will be identical whether we shuffle the validation set or not. Since shuffling takes extra time, it makes no sense to shuffle the validation data.\n",
    "\n",
    "We’ll use a batch size for the validation set that is twice as large as that for the training set. This is because the validation set does not need backpropagation and thus takes less memory (it doesn’t need to store the gradients). We take advantage of this to use a larger batch size and compute the loss more quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TensorDataset(x_train, y_train)\n",
    "train_dl = DataLoader(train_ds, batch_size=bs)\n",
    "\n",
    "val_ds = TensorDataset(x_val, y_val)\n",
    "val_dl = DataLoader(val_ds, batch_size=bs*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will calculate and print the validation loss at the end of each epoch.\n",
    "\n",
    "(Note that we always call model.train() before training, and model.eval() before inference, because these are used by layers such as nn.BatchNorm2d and nn.Dropout to ensure appropriate behaviour for these different phases.)\n",
    "\n",
    "model.eval(): switch off dropout and batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(0.4331)\n",
      "1 tensor(0.3675)\n"
     ]
    }
   ],
   "source": [
    "model, opt = get_model()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for xb, yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = loss_func(preds, yb)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    model.eval()    \n",
    "    with torch.no_grad():\n",
    "        val_loss = sum((loss_func(model(xb), yb) for xb, yb in val_dl))\n",
    "            \n",
    "    print(epoch, val_loss/len(val_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create fit() and get_data()\n",
    "We’ll now do a little refactoring of our own. Since we go through a similar process twice of calculating the loss for both the training set and the validation set, let’s make that into its own function, loss_batch, which computes the loss for one batch.\n",
    "\n",
    "We pass an optimizer in for the training set, and use it to perform backprop. For the validation set, we don’t pass an optimizer, so the method doesn’t perform backprop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None):\n",
    "    loss = loss_func(model(xb), yb)\n",
    "    \n",
    "    if opt:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        \n",
    "    return loss.item(), len(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fit(epochs, model, loss_func, train_dl, val_dl, opt):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        losses, nums = zip(*[loss_batch(model, loss_func, xb, yb, opt) for xb, yb in train_dl])\n",
    "        train_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            losses, nums = zip(*[loss_batch(model, loss_func, xb, yb) for xb, yb in val_dl])\n",
    "        val_loss = np.sum(np.multiply(losses, nums)) / np.sum(nums) # already cut-off\n",
    "    \n",
    "        print(epoch, train_loss, val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_data returns dataloaders for the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(train_ds, val_ds, bs):\n",
    "    return (DataLoader(train_ds, shuffle=True, batch_size=bs),\n",
    "            DataLoader(val_ds, batch_size=bs*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, our whole process of obtaining the data loaders and fitting the model can be run in 3 lines of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.7225038082313537 0.4331731245517731\n",
      "1 0.43638575025558474 0.3694142238140106\n"
     ]
    }
   ],
   "source": [
    "train_dl, val_dl = get_data(train_ds, val_ds, bs)\n",
    "model, opt = get_model()\n",
    "fit(epochs, model, loss_func, train_dl, val_dl, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Switch to CNN\n",
    "We are now going to build our neural network with three convolutional layers. Because none of the functions in the previous section assume anything about the model form, we’ll be able to use them to train a CNN without any modification.\n",
    "\n",
    "We will use Pytorch’s predefined Conv2d class as our convolutional layer. We define a CNN with 3 convolutional layers. Each convolution is followed by a ReLU. At the end, we perform an average pooling. (Note that view is PyTorch’s version of numpy’s reshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mnist_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        xb = xb.view(-1, 1, 28, 28)\n",
    "        xb = F.relu(self.conv1(xb))\n",
    "        xb = F.relu(self.conv2(xb))\n",
    "        xb = F.relu(self.conv3(xb))\n",
    "        xb = F.avg_pool2d(xb, 4)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "lr = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Momentum is a variation on stochastic gradient descent that takes previous updates into account as well and generally leads to faster training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8729121491622924 0.2847791933774948\n",
      "1 0.28166804943084717 0.20031915376782417\n"
     ]
    }
   ],
   "source": [
    "model = Mnist_CNN()\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, train_dl, val_dl, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nn.Sequential\n",
    "torch.nn has another handy class we can use to simply our code: Sequential . A Sequential object runs each of the modules contained within it, in a sequential manner. This is a simpler way of writing our neural network.\n",
    "\n",
    "To take advantage of this, we need to be able to easily define a custom layer from a given function. For instance, PyTorch doesn’t have a view layer, and we need to create one for our network. Lambda will create a layer that we can then use when defining a network with Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layer to take adaventage of nn.Sequential \n",
    "class Lambda(nn.Module):\n",
    "    \n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n",
    "    \n",
    "def preprocess(x):\n",
    "    return x.view(-1, 1, 28, 28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model created with Sequential is simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8247662519741058 0.33707464841604234\n",
      "1 0.31916908583164216 0.23437593964338302\n"
     ]
    }
   ],
   "source": [
    "model = nn.Sequential(\n",
    "    Lambda(preprocess),\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AvgPool2d(4),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "fit(epochs, model, loss_func, train_dl, val_dl, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapping DataLoader\n",
    "Our CNN is fairly concise, but it only works with MNIST, because:\n",
    "It assumes the input is a 28*28 long vector\n",
    "It assumes that the final CNN grid size is 4*4 (since that’s the average\n",
    "pooling kernel size we used)\n",
    "\n",
    "Let’s get rid of these two assumptions, so our model works with any 2d single channel image. First, we can remove the initial Lambda layer but moving the data preprocessing into a generator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tranform the input \n",
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28), y\n",
    "\n",
    "# this generator takes the function and dl to transform it \n",
    "class WrappedDataloader:\n",
    "    \n",
    "    def __init__(self, dl, func):\n",
    "        self.dl = dl\n",
    "        self.func = func\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        batches = iter(self.dl)\n",
    "        for b in batches:\n",
    "            yield self.func(*b)\n",
    "            \n",
    "train_dl, val_dl = get_data(train_ds, val_ds, bs)\n",
    "train_dl = WrappedDataloader(train_dl, preprocess)\n",
    "val_dl = WrappedDataloader(val_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can replace nn.AvgPool2d with nn.AdaptiveAvgPool2d, which allows us to define the size of the output tensor we want, rather than the input tensor we have. As a result, our model will work with any size input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 10, kernel_size=3, stride=2, padding=1),\n",
    "    nn.ReLU(),\n",
    "    nn.AdaptiveAvgPool2d(1),\n",
    "    Lambda(lambda x: x.view(x.size(0), -1)),\n",
    ")\n",
    "\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.8983209691810607 0.3518966914176941\n",
      "1 0.34042690168380735 0.279534934258461\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, train_dl, val_dl, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using your GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to move out batches to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(x, y):\n",
    "    return x.view(-1, 1, 28, 28).to(dev), y.to(dev)\n",
    "\n",
    "train_dl, val_dl = get_data(train_ds, val_ds, bs)\n",
    "train_dl = WrappedDataloader(train_dl, preprocess)\n",
    "val_dl = WrappedDataloader(val_dl, preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we need to move the model to gpu as well, nut never during testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** We need to move batches and model to gpu during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(dev)\n",
    "opt = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.25603091958999635 0.2001285798072815\n",
      "1 0.2145339176750183 0.18912224473953246\n"
     ]
    }
   ],
   "source": [
    "fit(epochs, model, loss_func, train_dl, val_dl, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, there are many things you’ll want to add, such as data augmentation, hyperparameter tuning, monitoring training, transfer learning, and so forth. These features are available in the fastai library, which has been developed using the same design approach shown in this tutorial, providing a natural next step for practitioners looking to take their models further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepL] *",
   "language": "python",
   "name": "conda-env-deepL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
