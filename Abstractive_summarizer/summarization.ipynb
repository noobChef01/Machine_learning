{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torchtext import data, vocab\n",
    "from torch import optim\n",
    "from torchtext.vocab import Vectors\n",
    "import torch.nn.functional as F\n",
    "\n",
    "dev = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declare the directory path to dataset  \n",
    "DATA_PATH = 'data/'\n",
    "SAMPLE_DATA_PATH = f'{DATA_PATH}sample_data/'\n",
    "PROCESSED_DATA_PATH = f'{DATA_PATH}processed_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enter the processed data absolute path here\n",
    "path = f'{SAMPLE_DATA_PATH}'\n",
    "\n",
    "# enter the absolute path to the embeddings\n",
    "emb_path = 'glove/glove.6B.300d.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep source and target Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer = data.get_tokenizer('spacy')\n",
    "TEXT = data.Field(tokenize=tokenizer, lower=True, eos_token='_eos_')\n",
    "\n",
    "\n",
    "trn_data_fields = [(\"source\", TEXT),\n",
    "                   (\"target\", TEXT)]\n",
    "\n",
    "trn, vld = data.TabularDataset.splits(path=path,\n",
    "                                     train='train.csv', validation='valid.csv',\n",
    "                                     format='csv', skip_header=True, fields=trn_data_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['chris', 'martin', 'claimed', 'three', 'wickets', 'in', 'the', 'first', '#', '#', 'minutes', 'of', 'the', 'first', 'test', 'cricket', 'between', 'new', 'zealand', 'and', 'bangladesh', 'on', 'friday', 'to', 'help', 'send', 'the', 'tourists', 'to', 'lunch', 'at', '#', '#', 'for', 'four', '.']\n",
      "['bangladesh', '#', '#', '-', '#', 'at', 'lunch', 'on', '#', 'st', 'day', '#', 'st', 'test']\n"
     ]
    }
   ],
   "source": [
    "# a sample of the preprocessed data\n",
    "print(trn[1].source)\n",
    "print(trn[1].target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embs(file_path):\n",
    "    word_embeddings = {}\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "    f.close()\n",
    "    return word_embeddings\n",
    "\n",
    "# get the embeddings\n",
    "vectors = get_embs(emb_path)\n",
    "\n",
    "vec_obj = Vectors(emb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TEXT.build_vocab(trn, vectors=vec_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#', 113),\n",
       " ('the', 103),\n",
       " ('.', 84),\n",
       " ('of', 71),\n",
       " (',', 68),\n",
       " ('a', 59),\n",
       " ('in', 55),\n",
       " ('to', 50),\n",
       " ('and', 36),\n",
       " ('-', 34)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10 most frequent words in the vocab\n",
    "TEXT.vocab.freqs.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set batch size\n",
    "batch_size = 45\n",
    "\n",
    "train_iter, val_iter = data.BucketIterator.splits(\n",
    "                        (trn, vld), batch_sizes=(batch_size, int(batch_size*1.6)),\n",
    "                        device='cuda' if torch.cuda.is_available() else \"cpu\", \n",
    "                        sort_key=lambda x: len(x.source),\n",
    "                        shuffle=True, sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader class\n",
    "class BatchTuple():\n",
    "    def __init__(self, dataset, x_var, y_var):\n",
    "        self.dataset, self.x_var, self.y_var = dataset, x_var, y_var\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.dataset:\n",
    "            x = getattr(batch, self.x_var) \n",
    "            y = getattr(batch, self.y_var)                 \n",
    "            yield (x, y)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns tuple of article-title pair tensors\n",
    "trn_dl = BatchTuple(train_iter, \"source\", \"target\")\n",
    "val_dl = BatchTuple(val_iter, \"source\", \"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 19]), torch.Size([14, 19]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(trn_dl.__iter__())\n",
    "x.size(), y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source:\n",
      "the morning began with an embrace and negotiations involving pat conroy and his latest novel , `` beach music . _eos_ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "\n",
      "corresponding tensor:\n",
      "[  4 813 471  26  22 623  11 822 740 867 544  11  23  87 836   7  29 469\n",
      " 817   5   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
      "   1   1   1   1   1   1   1   1   1   1   1   1] \n",
      "\n",
      "target:\n",
      "a long schmooze with booksellers _eos_ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> \n",
      "\n",
      "corresponding tensor:\n",
      "[  8  89 960  26 482   2   1   1   1   1   1   1   1   1] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#lets look at an example pair\n",
    "sample_source = x.transpose(1,0)[0].data.cpu().numpy()\n",
    "sample_target = y.transpose(1,0)[0].data.cpu().numpy()\n",
    "\n",
    "print(\"source:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(' '.join([TEXT.vocab.itos[o] for o in sample_source]), sample_source))\n",
    "print(\"target:\\n%s \\n\\ncorresponding tensor:\\n%s \\n\" %(' '.join([TEXT.vocab.itos[o] for o in sample_target]), sample_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set maximum target summary size \n",
    "its = [next(trn_dl.__iter__())[1] for i in range(10)]\n",
    "max_tgt_len = int(np.percentile([its[o].size()[0] for o in range(len(its))], 99))\n",
    "max_tgt_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model: Seq2Seq model with bi-GRU(RNN), added  teacher forking and Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb\n",
    "\n",
    "def rand_t(*sz): return torch.randn(sz)/math.sqrt(sz[0])\n",
    "def rand_p(*sz): return nn.Parameter(rand_t(*sz))\n",
    "\n",
    "class Seq2SeqAttnBiRNN(nn.Module):\n",
    "    def __init__(self, vecs, itos, em_sz, nh, out_sl, nl=2):\n",
    "        super().__init__()\n",
    "        self.emb_enc = create_emb(vecs, itos, em_sz)\n",
    "        self.nl,self.nh,self.out_sl = nl,nh,out_sl\n",
    "        self.gru_enc = nn.GRU(em_sz, nh, num_layers=nl, \n",
    "                              dropout=0.25, bidirectional=True)\n",
    "        self.out_enc = nn.Linear(nh*2, em_sz, bias=False)\n",
    "        \n",
    "        self.drop_enc = nn.Dropout(0.25)\n",
    "        self.emb_dec = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "        self.gru_dec = nn.GRU(em_sz, em_sz, num_layers=nl, \n",
    "                              dropout=0.1)\n",
    "        self.emb_enc_drop = nn.Dropout(0.15)\n",
    "        self.out_drop = nn.Dropout(0.35)\n",
    "        self.out = nn.Linear(em_sz, len(itos))\n",
    "        \n",
    "        self.emb_dec.weight  = self.emb_enc.weight\n",
    "        self.out.weight.data = self.emb_dec.weight.data\n",
    "        \n",
    "        self.W1 = rand_p(nh*2, em_sz)\n",
    "        self.l2 = nn.Linear(em_sz, em_sz)\n",
    "        self.l3 = nn.Linear(em_sz+nh*2, em_sz)\n",
    "        self.V = rand_p(em_sz)\n",
    "        self.pr_force = 1.\n",
    "        \n",
    "    def forward(self, inp, y=None):\n",
    "        sl,bs = inp.size()\n",
    "        h = self.initHidden(bs).to(dev)\n",
    "        emb = self.emb_enc_drop(self.emb_enc(inp))\n",
    "        enc_out, h = self.gru_enc(emb, h)\n",
    "        h = h.view(2,2,bs,-1).permute(0,2,1,3).contiguous().view(2,bs,-1)\n",
    "        h = self.out_enc(self.drop_enc(h))\n",
    "        \n",
    "        dec_inp = torch.zeros(bs).long().to(dev)\n",
    "        res,attns = [],[]\n",
    "        w1e = enc_out @ self.W1\n",
    "        for i in range(self.out_sl):\n",
    "            w2h = self.l2(h[-1])\n",
    "            u = torch.tanh(w1e + w2h)\n",
    "            a = F.softmax(u @ self.V, 0)\n",
    "            attns.append(a)\n",
    "            Xa = (a.unsqueeze(2) * enc_out).sum(0)\n",
    "            emb = self.emb_dec(dec_inp)\n",
    "            wgt_enc = self.l3(torch.cat([emb, Xa], 1))\n",
    "            \n",
    "            outp, h = self.gru_dec(wgt_enc.unsqueeze(0), h)\n",
    "            outp = self.out(self.out_drop(outp[0]))\n",
    "            res.append(outp)\n",
    "            dec_inp = outp.data.max(1)[1]\n",
    "            if (dec_inp==1).all(): break\n",
    "            if (y is not None) and (np.random.random()<self.pr_force):\n",
    "                if i>=len(y): break\n",
    "                dec_inp = y[i].to(dev)\n",
    "        return torch.stack(res)\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        return torch.zeros(self.nl*2, bs, self.nh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define loss and fit function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seq_loss(input, target):\n",
    "    sl,bs = target.size()\n",
    "    sl_in,bs_in,nc = input.size()\n",
    "    if sl>sl_in: input = F.pad(input, (0,0,0,0,0,sl-sl_in))\n",
    "    input = input[:sl]\n",
    "    return F.cross_entropy(input.view(-1,nc), target.view(-1))#, ignore_index=1)\n",
    "\n",
    "\n",
    "def loss_batch(model, loss_func, xb, yb, opt=None, inf=False):\n",
    "    if inf: loss = loss_func(model(xb, yb), yb)\n",
    "    else: loss = loss_func(model(xb), yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "    return loss.item(), len(xb)\n",
    "\n",
    "def fit(epochs, model, loss_func, opt, train_dl, valid_dl):\n",
    "    for epoch in range(epochs):\n",
    "        model.train() # imp to put for traning and eval time for batchnorm and dropout\n",
    "        tr_losses, tr_bsz = [], []\n",
    "        model.pr_force = (10-epoch)*0.1 if epoch<10 else 0\n",
    "        inf = True if epoch<10 else False\n",
    "        for xb, yb in train_dl:\n",
    "            loss, bs = loss_batch(model, loss_func, xb, yb, opt, inf=inf)\n",
    "            tr_losses.append(loss); tr_bsz.append(bs)\n",
    "            \n",
    "        model.eval()\n",
    "        #inf = False\n",
    "        with torch.no_grad():\n",
    "            losses, bsz = zip(*(loss_batch(model, loss_func, xb, yb, inf=True) for xb, yb in valid_dl))\n",
    "        valid_loss = np.sum(np.multiply(losses, bsz)) / np.sum(bsz)\n",
    "        train_loss = np.sum(np.multiply(tr_losses, tr_bsz)) / np.sum(tr_bsz)\n",
    "        print(f\"epoch:{epoch}\", f'train_loss:{train_loss}',f'valid_loss:{valid_loss}') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 ['a\\\\/h#n', '-member', '-nation', '-year']\n",
      "epoch:0 train_loss:19.909557630430978 valid_loss:22.819141387939453\n",
      "epoch:1 train_loss:23.67210442165159 valid_loss:18.611751556396484\n",
      "epoch:2 train_loss:22.196086019839882 valid_loss:22.349088668823242\n",
      "epoch:3 train_loss:16.74916620074578 valid_loss:20.890520095825195\n",
      "epoch:4 train_loss:14.641716663654034 valid_loss:14.591445922851562\n",
      "epoch:5 train_loss:10.947546203181428 valid_loss:11.754252433776855\n",
      "epoch:6 train_loss:7.573131341200608 valid_loss:9.427680015563965\n",
      "epoch:7 train_loss:7.496777407328287 valid_loss:13.132740020751953\n",
      "epoch:8 train_loss:5.938907722257218 valid_loss:14.67599868774414\n",
      "epoch:9 train_loss:5.9101277864896336 valid_loss:11.508200645446777\n",
      "epoch:10 train_loss:6.2073125659294845 valid_loss:8.656683921813965\n",
      "epoch:11 train_loss:5.421783034006754 valid_loss:8.24914264678955\n",
      "epoch:12 train_loss:6.65495096468458 valid_loss:11.582647323608398\n",
      "epoch:13 train_loss:5.79215853030865 valid_loss:8.480308532714844\n",
      "epoch:14 train_loss:5.93007116317749 valid_loss:13.00399398803711\n",
      "epoch:15 train_loss:7.135581448393048 valid_loss:7.691411972045898\n",
      "epoch:16 train_loss:7.040841498464908 valid_loss:7.855312824249268\n",
      "epoch:17 train_loss:7.023115544948938 valid_loss:7.879045486450195\n",
      "epoch:18 train_loss:6.565328616016316 valid_loss:8.288524627685547\n",
      "epoch:19 train_loss:6.909055599799523 valid_loss:9.36579704284668\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqAttnBiRNN(vectors, TEXT.vocab.itos, 300, 200, max_tgt_len).to(dev)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2, weight_decay=1e-1, betas=(0.9, 0.999))\n",
    "fit(20, model, seq2seq_loss, opt, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_pred(dl, k=1):\n",
    "    x,y = next(iter(dl))\n",
    "    probs = model(x)\n",
    "    preds = probs.max(2)[1].cpu().numpy()\n",
    "    x = np.array([i.cpu().numpy() for i in x])\n",
    "    y = np.array([i.cpu().numpy() for i in y])\n",
    "\n",
    "    # Inference\n",
    "    for i in range(k):\n",
    "        print('src:\\n')\n",
    "        print(' '.join([TEXT.vocab.itos[o] for o in x[:,i] if o != 1]))\n",
    "        print('\\ntarget:\\n')\n",
    "        print(' '.join([TEXT.vocab.itos[o] for o in y[:,i] if o != 1]))\n",
    "        print('\\npred:\\n')\n",
    "        print(' '.join([TEXT.vocab.itos[o] for o in preds[:,i] if o!=1]))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src:\n",
      "\n",
      "a light <unk> <unk> <unk> <unk> on wednesday , killing three people <unk> , the russian <unk> <unk> ministry said . _eos_\n",
      "\n",
      "target:\n",
      "\n",
      "light <unk> <unk> <unk> <unk> killing three _eos_\n",
      "\n",
      "pred:\n",
      "\n",
      "eu\n",
      "\n",
      "src:\n",
      "\n",
      "us <unk> of <unk> <unk> <unk> on sunday <unk> <unk> states to <unk> <unk> <unk> towards <unk> a peace <unk> with israel . _eos_\n",
      "\n",
      "target:\n",
      "\n",
      "<unk> <unk> <unk> states to <unk> <unk> for <unk> peace _eos_\n",
      "\n",
      "pred:\n",
      "\n",
      "china eu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_pred(val_dl, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
