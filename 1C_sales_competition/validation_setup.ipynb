{
  "cells": [
    {
      "metadata": {
        "_uuid": "2561fe8c675a5a35998ab719f562b557154899bf"
      },
      "cell_type": "markdown",
      "source": "## Load Libraries and Data"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "import gc\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 100)\nimport numpy as np\nfrom tqdm import tqdm_notebook\nfrom itertools import product\nfrom sklearn.preprocessing import LabelEncoder\n\ndata_folder = \"../input/\"\nitems = pd.read_csv(data_folder+'items.csv')\nshops = pd.read_csv(data_folder+'shops.csv')\ncats = pd.read_csv(data_folder+'item_categories.csv')\ntrain = pd.read_csv(data_folder+'sales_train.csv.gz', compression='gzip', header=0)\n# set index to ID to avoid droping it later\ntest  = pd.read_csv(data_folder+'test.csv.gz', compression='gzip', header=0).set_index('ID')",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "acaaf8d23ec107304b57b34516cad31e3cd54797"
      },
      "cell_type": "markdown",
      "source": "## Data cleaning and feature generation"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aba2248eed53b3affbb21ca25abfa58822331a1d"
      },
      "cell_type": "code",
      "source": "# remove outliers\ntrain = train[train.item_price < 59201.00]\ntrain = train[train.item_cnt_day < 625]\n\n# correct price of negative priced item\ntrain.loc[train.item_price < 0, 'item_price'] = 2499.00\n\n# correct shop ids\n# Жуковский ул. Чкалова 39м²\ntrain.loc[train.shop_id == 11, 'shop_id'] = 10\ntrain.loc[train.shop_id == 40, 'shop_id'] = 39\n# Якутск Орджоникидзе, 56\ntrain.loc[train.shop_id == 0, 'shop_id'] = 57\n# Якутск ТЦ \"Центральный\"\ntrain.loc[train.shop_id == 1, 'shop_id'] = 58\n# drop these in the shop details df\nshops = shops.drop([0,1,11,40], axis=0).reset_index(drop=True)\n\ndef get_icat(x):\n    split = x.split('-')\n    main = split[0].strip()\n    if len(split) > 1:\n        sub = split[1].strip()\n    else:\n        sub = main\n    return main, sub\n\n# Extract shop location city and items main and sub category\n# correct shop name\nshops.loc[shops.shop_name == 'Сергиев Посад ТЦ \"7Я\"', 'shop_name'] = 'СергиевПосад ТЦ \"7Я\"'\n# extract city code\nshops['city'] = shops.shop_name.apply(lambda x: x.split(' ')[0].strip())\nshops['city_code'] = LabelEncoder().fit_transform(shops['city'])\nshops = shops[['shop_id', 'city_code']]\n\n# extract main and sub category code\nmain_sub = cats.item_category_name.apply(get_icat)\ncats['main'], cats['sub'] = [x[0] for x in main_sub], [x[1] for x in main_sub]\ncats['main_code'] = LabelEncoder().fit_transform(cats['main'])\ncats['sub_code'] = LabelEncoder().fit_transform(cats['sub'])\ncats = cats[['item_category_id', 'main_code', 'sub_code']]\nitems = items[['item_id', 'item_category_id']]\ndel main_sub\ngc.collect()\n\n# add date_block_num to test\ntest['date_block_num'] = 34\n\n# give train similar structure as test\nindex_cols = ['date_block_num', 'shop_id', 'item_id']\ngrid = []\nfor i in range(34):\n    curr_shops = train.loc[train.date_block_num == i, 'shop_id'].unique()\n    curr_items = train.loc[train.date_block_num == i, 'item_id'].unique()\n    grid.append(np.array(list(product(*[[i], curr_shops, curr_items])), dtype=np.int16))\n\ngrid = pd.DataFrame(np.vstack(grid), columns=index_cols)\ngrid = grid.sort_values(index_cols)\n\n# append test to grid \ngrid = pd.concat([grid,test], ignore_index=True, sort=False, keys=index_cols) \ngrid['date_block_num'] = grid['date_block_num'].astype(np.int8)\ngrid['shop_id'] = grid['shop_id'].astype(np.int8)\ngrid['item_id'] = grid['item_id'].astype(np.int16)\n\ndel test\ngc.collect()\n\n# season feature\nseasons = pd.DataFrame()\nseasons['date_block_num'] = range(35)\nmonth = seasons.date_block_num % 12 + 1\nseasons.loc[month.isin([12,1,2,3]), 'season'] = 0    # 'winter'\nseasons.loc[month.isin([6,7,8]), 'season'] = 1  #'summer'\nseasons.loc[month.isin([4,5]), 'season'] = 2 #'spring'\nseasons.loc[month.isin([9,10,11]), 'season'] = 3 #'autumn'\n\n# revenue feature\ntrain['revenue'] = train.item_cnt_day * train.item_price\n\n# prices ending with 9\nstr_prices   = train.item_price.astype(str)\nstr_prices   = str_prices.apply(lambda x: x.split('.')[0])\nends_with_9  = str_prices.apply(lambda x: x.endswith('9'))\n# take items with prices ending with 9 more than 70% of the time\nitems['end_with_9'] = items['item_id'].map((ends_with_9.groupby(train.item_id).mean() > 0.70) * 1)\nitems.end_with_9.fillna(1, inplace=True)\n\ndel str_prices, ends_with_9\ngc.collect()\n\n# import math\n# def cube_root(x):\n#     if x > 0:\n#         return math.pow(x, float(1)/3)\n#     elif x < 0:\n#         return -math.pow(abs(x), float(1)/3)\n#     else:\n#         return 0\n\n# # pre-process the numerical features\n# train['item_price'] = np.log(train.item_price)\n# train['item_cnt_day'] = train.item_cnt_day.apply(cube_root)\n# train['revenue'] = train.revenue.apply(cube_root)\n# drop unwanted cols\ntrain = train.drop(['date', 'item_price'], axis=1)\n\n# add the generated features into grid\ngrid = pd.merge(grid, items, on='item_id', how='left')\ngrid = pd.merge(grid, seasons, on='date_block_num', how='left')\ngrid = pd.merge(grid, cats, on='item_category_id', how='left')\ngrid = pd.merge(grid, shops, on='shop_id', how='left')\n\n# downcast the datatypes\ngrid['item_category_id'] = grid['item_category_id'].astype(np.int8)\ngrid['end_with_9'] = grid['end_with_9'].astype(np.int8)\ngrid['season'] = grid['season'].astype(np.int8)\ngrid['main_code'] = grid['main_code'].astype(np.int8)\ngrid['sub_code'] = grid['sub_code'].astype(np.int8)\ngrid['city_code'] = grid['city_code'].astype(np.int8)\n\ndel items, cats, seasons, shops\ngc.collect()",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "126"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "5ea70369ea14f353fadb908cafaacd530f3a1586"
      },
      "cell_type": "markdown",
      "source": "### Aggregate sales data"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4ba0e4df92a8c9cc8db11c72471566acf08b69e3"
      },
      "cell_type": "code",
      "source": "# aggregate sale counts\ngroup = train.groupby(index_cols).agg({'item_cnt_day': 'sum'})\ngroup.columns = ['item_cnt_month']\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=index_cols, how='left').fillna(0)\ngrid['item_cnt_month'] = grid['item_cnt_month'].clip(0,20) \n\n# revenue aggregates\ngroup = train.groupby(index_cols).agg({'revenue': 'mean'})\ngroup.columns = ['mean_revenue']\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=index_cols, how='left').fillna(0)\n\n# item revenue aggreagtes\ngroup = train.groupby(['date_block_num', 'item_id']).agg({'revenue': 'mean'})\ngroup.columns = ['item_mean_revenue']\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id'], how='left').fillna(0)\n\n# shop revenue aggregates\ngroup = train.groupby(['date_block_num', 'shop_id']).agg({'revenue': 'mean'})\ngroup.columns = ['shop_mean_revenue']\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'shop_id'], how='left').fillna(0)\ndel train, group\ngc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "399ff7809fea7bf2276efabdcbdaebbb7a53fb80"
      },
      "cell_type": "markdown",
      "source": "### Mean encodings"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "235ea9b3d7f2f0a4ebe1cd5579351d0d80097129"
      },
      "cell_type": "code",
      "source": "from sklearn.model_selection import KFold\ngb_mean = grid.loc[grid.date_block_num < 34, 'item_cnt_month'].mean()\n\ndef mean_encode_regul(cat_feat, all_data):\n    ran_ins = np.random.RandomState(123)\n    kf = KFold(n_splits=5, shuffle=False, random_state=ran_ins)\n    encoded_feature = pd.Series()\n    \n    for tr_idx, val_idx in kf.split(all_data.loc[all_data.date_block_num < 34, :]):\n        tr, val = all_data.iloc[tr_idx], all_data.iloc[val_idx]\n        means = tr.groupby(cat_feat).item_cnt_month.mean()\n        encoded_feature = encoded_feature.append(pd.Series(val['item_id'].map(means)))\n        \n    return encoded_feature",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f8d10c5545421672acdc1ff0d17a12da4a4ac6d9"
      },
      "cell_type": "code",
      "source": "# single categorical column encodings\nmenc_cols = ['item_id','date_block_num', 'main_code', 'shop_id', 'item_category_id', 'end_with_9', 'season', 'sub_code', 'city_code']\n\nfor col in tqdm_notebook(menc_cols):\n    grid[col+'_enc'] = mean_encode_regul(col, grid).fillna(gb_mean)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcf7bcf92b6159400f4aa0f43cb3682af53a12a6"
      },
      "cell_type": "code",
      "source": "# combiation of categorical columns encodings\n# item-month encoding\ngroup = grid.groupby(['date_block_num', 'item_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['item_month_enc']\ngroup['item_month_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id'], how='left')\n\n# shop_month encoding\ngroup = grid.groupby(['date_block_num', 'shop_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['shop_month_enc']\ngroup['shop_month_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'shop_id'], how='left')\n\n\n# itc-month encoding\ngroup = grid.groupby(['date_block_num', 'item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['itc_month_enc']\ngroup['itc_month_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_category_id'], how='left')\n\n\n# dt-item-Itc encoding\ngroup = grid.groupby(['date_block_num', 'item_id','item_category_id']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_item_itc_enc']\ngroup['mon_item_itc_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id','item_category_id'], how='left')\n\n\n# dt-item-end_wit9 enc\ngroup = grid.groupby(['date_block_num', 'item_id','end_with_9']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_item_end9_enc']\ngroup['mon_item_end9_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id','end_with_9'], how='left')\n\n\n# dt-item-main-sub encoding\ngroup = grid.groupby(['date_block_num', 'item_id','main_code', 'sub_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_it_m-s_enc']\ngroup['mon_it_m-s_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id','main_code', 'sub_code'], how='left')\n\n\n# dt-item-main encoding\ngroup = grid.groupby(['date_block_num', 'item_id','main_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_it_m_enc']\ngroup['mon_it_m_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id','main_code'], how='left')\n\n\n# dt-item-sub encoding\ngroup = grid.groupby(['date_block_num', 'item_id','sub_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_it_s_enc']\ngroup['mon_it_s_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'item_id','sub_code'], how='left')\n\n      \n\n# dt-season encoding\ngroup = grid.groupby(['date_block_num', 'season']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_season_enc']\ngroup['mon_season_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'season'], how='left')\n\n\n# dt-sh-season encoding\ngroup = grid.groupby(['date_block_num', 'shop_id','season']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_sh_se_enc']\ngroup['mon_sh_se_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'shop_id','season'], how='left')\n\n\n# dt-sh-city encoding\ngroup = grid.groupby(['date_block_num', 'shop_id', 'city_code']).agg({'item_cnt_month': ['mean']})\ngroup.columns = ['mon_sh_cty_enc']\ngroup['mon_sh_cty_enc'].fillna(gb_mean, inplace=True)\ngroup.reset_index(inplace=True)\ngrid = pd.merge(grid, group, on=['date_block_num', 'shop_id', 'city_code'], how='left')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4f0d4cfd7a661e167997a8d78b2b9cec3f8c2e00"
      },
      "cell_type": "code",
      "source": "grid['mean_revenue'] = grid['mean_revenue'].astype(np.float32)\ngrid['item_mean_revenue'] = grid['item_mean_revenue'].astype(np.float32)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "fcf7bcf92b6159400f4aa0f43cb3682af53a12a6"
      },
      "cell_type": "code",
      "source": "# downcast the mean encodings and the target\nfor col in tqdm_notebook(grid.select_dtypes(include=float).columns):\n    grid[col] = grid[col].astype(np.float16)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7b1c4253d83a8ac0b7b5bf1202435f18de3272bd"
      },
      "cell_type": "markdown",
      "source": "### Lags"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "601c7ecc5cbfd949e80bb4875435f5b7408bdfde"
      },
      "cell_type": "code",
      "source": "def lag_feature(df, lags, col):\n    tmp = df[['date_block_num','shop_id','item_id',col]]\n    for i in lags:\n        shifted = tmp.copy()\n        shifted.columns = ['date_block_num','shop_id','item_id', col+'_lag_'+str(i)]\n        shifted['date_block_num'] += i\n        df = pd.merge(df, shifted, on=['date_block_num','shop_id','item_id'], how='left')\n    return df",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6f6286af7c7d50aebb354fb6a50d6a70287b0cad"
      },
      "cell_type": "code",
      "source": "#grid.drop(['item_category_id','end_with_9','season','main_code','sub_code','city_code'], axis=1,inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "10c950f437f9dc4d1ac9cec8cf50ae10dcd3c24e"
      },
      "cell_type": "code",
      "source": "# create lags\ncol_lags = [('item_id_enc', [2,3]), ('date_block_num_enc', [2,3]),('item_cnt_month', [1,2,3,6]),\\\n            ('main_code_enc', [2,3])]\n\nfor pair in tqdm_notebook(col_lags):\n    grid = lag_feature(grid, pair[1], pair[0])",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f5d33e8e96bd523048d0af08ce312415be03d8f4"
      },
      "cell_type": "code",
      "source": "col_lags = ['mean_revenue', 'item_mean_revenue', 'shop_mean_revenue','item_month_enc',\\\n            'shop_month_enc', 'itc_month_enc', 'mon_item_itc_enc','mon_item_end9_enc',\\\n            'mon_it_m-s_enc', 'mon_it_m_enc', 'mon_it_s_enc','mon_season_enc', \\\n            'mon_sh_se_enc', 'mon_sh_cty_enc', 'shop_id_enc', 'item_category_id_enc',\n           'end_with_9_enc', 'season_enc', 'sub_code_enc', 'city_code_enc']\n\nfor col in tqdm_notebook(col_lags):\n    grid = lag_feature(grid, [1,2,3], col)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ec40944043e8df2e7dab2490acdfb1a3e398ce5d"
      },
      "cell_type": "code",
      "source": "# drop unwanted cols\ncols_to_drop = [col for col in grid.columns if col.endswith('enc')] + ['mean_revenue', 'item_mean_revenue', 'shop_mean_revenue']\ngrid.drop(cols_to_drop, axis=1, inplace=True)\ngrid = grid[grid.date_block_num > 5]\ngrid.fillna(0, inplace=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8463ceca0a275dc713bb2e1ffcfdaa542b54985f"
      },
      "cell_type": "code",
      "source": "gc.collect()",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "060818a57530d0268112b48da7751374649b4148"
      },
      "cell_type": "code",
      "source": "# save the built dataframe\ngrid.to_pickle('grid.pkl')",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}