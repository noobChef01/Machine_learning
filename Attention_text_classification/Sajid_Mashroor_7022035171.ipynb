{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "\n",
    "**Problem Statement:** Make a classifier which takes in a job description and gives the department name for it.\n",
    "*   Use a neural network model\n",
    "*   Make use of a pre-trained Word Embeddings (example: Word2Vec, GloVe, etc.)\n",
    "*   Calculate the accuracy on a test set (data not used to train the model)\n",
    "\n",
    "**Problem Solving Approach:** \n",
    "_Provide a brief description of steps you followed for solving this problem_\n",
    "1. first make a dataframe by extarcting the descriptions, keywords and id from JDs \n",
    "    and combining this with the labels to form the datset. \n",
    "2. Pre-processing steps: remove email, replace contractions, punctuations, lemmatize,\n",
    "    remove stopwords, symbols and extra spaces.\n",
    "3. dropped duplicate descriptions and kept lables with more than 7(median) count\n",
    "4. Used LSTM + Attention neural network architecture.\n",
    "5. Used class weights in order to the balance the Labels\n",
    "6. Trained unitl overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part I: Text Preprocessing\n",
    "\n",
    "_Include all text preprocesing steps like processing of json,csv files & data cleaning in this part._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import neccessary packages in below cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import warnings\n",
    "from fastai.text import *\n",
    "from fastai.text import Tokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Job Departments\n",
    "label_df = pd.read_csv('data/document_departments.csv') \n",
    "label_df.columns = ['id', 'Department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read JD\n",
    "def get_description(path): \n",
    "    data = {'description': [], 'id': [], 'job_keywords':[]}\n",
    "    for filename in glob.glob(path):\n",
    "        with open(filename, 'r') as json_file:\n",
    "            jd_data = json.load(json_file)\n",
    "            data['description'].append(jd_data['jd_information']['description'])\n",
    "            data['id'].append(int(jd_data['_id']))\n",
    "            data['job_keywords'].append(' '.join(jd_data['api_data']['job_keywords']))\n",
    "\n",
    "    return data\n",
    "\n",
    "jd_df = pd.DataFrame.from_dict(get_description('data/docs/*.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data together and re-index\n",
    "data = pd.merge(jd_df, label_df, on='id', how='inner').set_index('id')\n",
    "data.description = data.description+' '+ data.job_keywords\n",
    "data.drop(['job_keywords'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5922081</th>\n",
       "      <td>Urgent positions for Travel Executive at Saane...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6523883</th>\n",
       "      <td>Dear Candidate,Greetings From Continental Immi...</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6600981</th>\n",
       "      <td>We Have urgent poitions for Ticketing Executiv...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6686185</th>\n",
       "      <td>We Have Urgent positions for Travel booking cu...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6726409</th>\n",
       "      <td>Experience in Travel Industry.We have urgent o...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               description        Department\n",
       "id                                                                          \n",
       "5922081  Urgent positions for Travel Executive at Saane...  Customer service\n",
       "6523883  Dear Candidate,Greetings From Continental Immi...             Sales\n",
       "6600981  We Have urgent poitions for Ticketing Executiv...         Ticketing\n",
       "6686185  We Have Urgent positions for Travel booking cu...  Customer service\n",
       "6726409  Experience in Travel Industry.We have urgent o...         Ticketing"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the text descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from collections import Counter \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "contarct_dict = {\"it's\": \"it is\", \"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "lmz = WordNetLemmatizer()\n",
    "\n",
    "# helper functions for preprocessing\n",
    "def rm_symb_punc(text):\n",
    "    pattern = r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def email(text):\n",
    "    pattern = r'\\S*@\\S*\\s?'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "\n",
    "def replace_contractions(text, contraction_dict=contarct_dict):\n",
    "    contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "\n",
    "def rm_useless_spaces(t:str) -> str:\n",
    "    \"Remove multiple spaces in `t`.\"\n",
    "    return re.sub(' {2,}', ' ', t)\n",
    "\n",
    "def rm_stop_lemma(sen):\n",
    "    sen_new = \" \".join([lmz.lemmatize(w) for w in sen if w not in stop_words and (len(w)>2)])\n",
    "    return sen_new\n",
    "\n",
    "def pr_proc(text):\n",
    "    return rm_stop_lemma(rm_useless_spaces(rm_symb_punc(email(replace_contractions(text.lower())))).split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(10)\n",
    "data.description = pool.map(pr_proc, data.description.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urgent position travel executive saanewaal loc...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear candidategreetings continental immigratio...</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urgent poitions ticketing executive tour trave...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urgent position travel booking cum client supp...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience travel industrywe urgent opening fo...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description        Department\n",
       "0  urgent position travel executive saanewaal loc...  Customer service\n",
       "1  dear candidategreetings continental immigratio...             Sales\n",
       "2  urgent poitions ticketing executive tour trave...         Ticketing\n",
       "3  urgent position travel booking cum client supp...  Customer service\n",
       "4  experience travel industrywe urgent opening fo...         Ticketing"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part II: Exploratoty Data Analysis\n",
    "\n",
    "_Include EDA steps like finding distribution of Departments in this part, you may also use plots for EDA._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Df Shape: (1162, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urgent position travel executive saanewaal loc...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear candidategreetings continental immigratio...</td>\n",
       "      <td>Sales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urgent poitions ticketing executive tour trave...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urgent position travel booking cum client supp...</td>\n",
       "      <td>Customer service</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience travel industrywe urgent opening fo...</td>\n",
       "      <td>Ticketing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description        Department\n",
       "0  urgent position travel executive saanewaal loc...  Customer service\n",
       "1  dear candidategreetings continental immigratio...             Sales\n",
       "2  urgent poitions ticketing executive tour trave...         Ticketing\n",
       "3  urgent position travel booking cum client supp...  Customer service\n",
       "4  experience travel industrywe urgent opening fo...         Ticketing"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Df Shape: {data.shape}');data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: number of null values 0\n",
      "Text: number of null values 0\n"
     ]
    }
   ],
   "source": [
    "# check for null values\n",
    "print(f'Label: number of null values {(data.Department == \"\").sum()}')\n",
    "print(f'Text: number of null values {(data.description == \"\").sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "943\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# check for unique values \n",
    "print(data.description.nunique())\n",
    "print(data.Department.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: Duplicates rows exist in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplcates\n",
    "data.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(955, 2)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75      immigration consultant sale consultantnbspwe s...\n",
       "293                             sale business development\n",
       "641     conducting sale international domestic holiday...\n",
       "704     cold calling negotiation area mapping prospect...\n",
       "895     digital marketing seo campaign content writer ...\n",
       "985     job descriptionnbspsend job like thisproviding...\n",
       "1068    person indepth understanding key social medial...\n",
       "1119    exe travel sale consultant travel sale consult...\n",
       "1125    candidate working seosmo based company candida...\n",
       "1126    candidate creative designing website template ...\n",
       "1141    key responsibility role selling online recruit...\n",
       "1143    job descriptionkey responsibility rolenbsp sel...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dup_descrip = data[data.description.duplicated()].description\n",
    "dup_descrip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: Job posts with same description but belonging to different department exist, keep one of them to make it multi-class classification    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(943, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop duplicate descriptions\n",
    "data = data.loc[data.description.drop_duplicates().index, :]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     30.000000\n",
      "mean      31.433333\n",
      "std       66.816622\n",
      "min        1.000000\n",
      "25%        2.000000\n",
      "50%        7.000000\n",
      "75%       34.000000\n",
      "max      319.000000\n",
      "Name: Department, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# label distribution\n",
    "print(data.Department.value_counts().describe())\n",
    "plt.boxplot(data.Department.value_counts());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: Keep labels which appear more than 5 times (median). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop labels with insufficient data\n",
    "msk = data.Department.value_counts()[data.Department.value_counts() > 7].index\n",
    "data = data.loc[data.Department.isin(msk), :]\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of labels after drop of unimportant ines\n",
    "data.Department.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part III: Modelling & Evaluation\n",
    "\n",
    "_Include all model prepration & evaluation steps in this part._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode the labels \n",
    "lbl_en = LabelEncoder()\n",
    "data.Department = lbl_en.fit_transform(data.Department)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>Department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urgent position travel executive saanewaal loc...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear candidategreetings continental immigratio...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urgent poitions ticketing executive tour trave...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urgent position travel booking cum client supp...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>experience travel industrywe urgent opening fo...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  Department\n",
       "0  urgent position travel executive saanewaal loc...           3\n",
       "1  dear candidategreetings continental immigratio...          12\n",
       "2  urgent poitions ticketing executive tour trave...          14\n",
       "3  urgent position travel booking cum client supp...           3\n",
       "4  experience travel industrywe urgent opening fo...          14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into train , validation and test sets\n",
    "train, test = train_test_split(data.loc[:, ['Department', 'description']], test_size=0.15, random_state=0, shuffle=True, stratify=data.Department) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>xxbos arsenius skill capital hiring client relation xxunk delhi mumbai xxunk lac panbspindustry corporate amp business xxunk customer relationship management crm amp xxunk xxunk managing aspect assigned client account include limited client retention contract negotiation implementation business xxunk sale product service financials budget billing payment profitability business planning review establishing relationship key decision maker multiple region staff development business continuance escalation operational xxunk duty responsibility establish amp maintain relationship responsible</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos primary role tsmtso prospect new clientsfranchisetravel agent networking reference cold callingadvertising mean generating interest potential client must plan persuasive approach andpitches convince potential client business company must develop rapport new client andset target sale provide support continually improve relationship also required grow andretain existing account presenting new solution service clientstsmtso work mid senior levelmanagement marketing technical staff heshe may manage activity others responsible developing businessfor company strategic planning key</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos dear candidatenbsphope wellnbspwe came across profile portal amp wanted share role younbsplocation ndash bangalorenbspclientfounded clientis worldwide leader vacation exchange provider travel service business consumer unique breadth scope accommodation choice type location clientoffers global community three million member quality vacation experience resort worldwide weekforweek pointsbased exchange network growth partner clientdelivers customized integrated resultsdriven solution meet need exceed expectation affiliate consumer worldwide clientis division clientglobal vacation network global leader nonhotel leisure</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos walk copy xxunk interglobe xxunk business xxunk ground xxunk road pune ndash near xxunk xxunk stand xxunk xxunk xxunk monday xxunk person xxunk xxunk number xxunk technology looking process associate handle sale customer care process end end airline operation position based pune report team leader xxunk bpo position responsible handling customer care related issue reservation web site support bulk booking notification xxunk credit card verification queue management email management</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>xxbos apply interested work new xxunk responsible selling holiday package domestic amp xxunk tour executive must good knowledge indian international destination detail responsibility domestic xxunk booking receiving xxunk providing client best possible routing destination competitive fare available market designing itinerary hotel booking amp costing contracting hotel managing supplier effectively communicating order get timely confirmation candidate well versed operational aspect booking capable web query walkin client query make professional accurate cost</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# prep data for the model\n",
    "md = TextClasDataBunch.from_df(path='.', train_df=train, valid_df=test, bs=128)\n",
    "md.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod pre-trained Embeddings\n",
    "def get_embs(file_path):\n",
    "    word_embeddings = {}\n",
    "    f = open(file_path, encoding='utf-8')\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        word_embeddings[word] = coefs\n",
    "    f.close()\n",
    "    return word_embeddings\n",
    "\n",
    "vectors = get_embs('glove/glove.6B.300d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper func to load only required embeddings\n",
    "def create_emb(vecs, itos, em_sz):\n",
    "    emb = nn.Embedding(len(itos), em_sz, padding_idx=1)\n",
    "    wgts = emb.weight.data\n",
    "    miss = []\n",
    "    for i,w in enumerate(itos):\n",
    "        try: wgts[i] = torch.from_numpy(vecs[w])\n",
    "        except: miss.append(w)\n",
    "    print(len(miss),miss[5:10])\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BnLinLy(nn.Module):\n",
    "    def __init__(self, ni, no):\n",
    "        super().__init__()\n",
    "        self.lin = nn.Linear(ni, no)\n",
    "        self.bn = nn.BatchNorm1d(no)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.bn(F.relu(self.lin(x)))\n",
    "    \n",
    "class ResnetLy(BnLinLy):\n",
    "    def forward(self, x): return x + super().forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class AttenLSTM(nn.Module):\n",
    "    def __init__(self, vocab_ln,nh, nc, vecs, itos,layers,emb_sz=300):\n",
    "        super().__init__()\n",
    "        self.nh, self.nc = nh, nc\n",
    "        self.emb = create_emb(vecs, itos, emb_sz)\n",
    "        self.enc = nn.LSTM(emb_sz, nh, dropout=0.5) \n",
    "        #self.lin = ResnetLy(nh, nh)\n",
    "        self.lin1 = nn.ModuleList([BnLinLy(layers[i], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.lin2 = nn.ModuleList([ResnetLy(layers[i+1], layers[i+1]) for i in range(len(layers)-1)])\n",
    "        self.out = nn.Linear(nh//2, nc)\n",
    "    \n",
    "    def attention_net(self, lstm_output, final_state):\n",
    "        '''\n",
    "        hidden.size() = (batch_size, hidden_size)\n",
    "        attn_weights.size() = (batch_size, num_seq)\n",
    "        soft_attn_weights.size() = (batch_size, num_seq)\n",
    "        new_hidden_state.size() = (batch_size, hidden_size)\n",
    "        '''\n",
    "        hidden = final_state.squeeze(0)\n",
    "        attn_weights = torch.bmm(lstm_output, hidden.unsqueeze(2)).squeeze(2)\n",
    "        soft_attn_weights = F.softmax(attn_weights, 1)\n",
    "        new_hidden_state = torch.bmm(lstm_output.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        return new_hidden_state\n",
    " \n",
    "    def forward(self, inp):\n",
    "        inp = inp.permute(1,0)\n",
    "        sl, bs = inp.size()\n",
    "        h = self.initHidden(bs)\n",
    "        emb = self.emb(inp)\n",
    "        outp, h = self.enc(emb, h)\n",
    "        outp = outp.permute(1,0,2)\n",
    "        attn_output = self.attention_net(outp, h[0])\n",
    "        for l1, l2 in zip(self.lin1, self.lin2):\n",
    "            attn_output = l2(l1(attn_output))\n",
    "        out = self.out(attn_output)\n",
    "        return out\n",
    "    \n",
    "    def initHidden(self, bs): \n",
    "        return torch.zeros(1, bs, self.nh).to('cuda'), torch.zeros(1, bs, self.nh).to('cuda')\n",
    "    \n",
    "    def res_layer(self):\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1042 ['xxmaj', 'xxup', 'xxrep', 'xxwrep', 'nbsp']\n"
     ]
    }
   ],
   "source": [
    "vocab_sz = len(md.train_dl.vocab.itos)\n",
    "# initialize model\n",
    "model = AttenLSTM(vocab_sz, nh=150, nc=15, vecs=vectors, itos=md.train_dl.vocab.itos, layers=[150, 75]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initailize weights for the classes (class imbalance)\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 data.Department.unique(),\n",
    "                                                 data.Department)\n",
    "\n",
    "class_weights = torch.FloatTensor(class_weights).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = Learner(md, model, loss_func= nn.CrossEntropyLoss(weight=class_weights), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 03:48 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>2.683739</th>\n",
       "    <th>2.637541</th>\n",
       "    <th>0.345588</th>\n",
       "    <th>00:44</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>2.425799</th>\n",
       "    <th>2.121215</th>\n",
       "    <th>0.360294</th>\n",
       "    <th>00:34</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>2</th>\n",
       "    <th>2.063377</th>\n",
       "    <th>1.369869</th>\n",
       "    <th>0.514706</th>\n",
       "    <th>00:37</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>3</th>\n",
       "    <th>1.794401</th>\n",
       "    <th>1.505891</th>\n",
       "    <th>0.367647</th>\n",
       "    <th>00:38</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>4</th>\n",
       "    <th>1.546192</th>\n",
       "    <th>1.237597</th>\n",
       "    <th>0.404412</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>5</th>\n",
       "    <th>1.372566</th>\n",
       "    <th>1.098870</th>\n",
       "    <th>0.470588</th>\n",
       "    <th>00:36</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(6,1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Total time: 01:22 <p><table style='width:375px; margin-bottom:10px'>\n",
       "  <tr>\n",
       "    <th>epoch</th>\n",
       "    <th>train_loss</th>\n",
       "    <th>valid_loss</th>\n",
       "    <th>accuracy</th>\n",
       "    <th>time</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>0</th>\n",
       "    <th>0.723185</th>\n",
       "    <th>1.027082</th>\n",
       "    <th>0.522059</th>\n",
       "    <th>00:38</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <th>1</th>\n",
       "    <th>0.668784</th>\n",
       "    <th>1.000522</th>\n",
       "    <th>0.536765</th>\n",
       "    <th>00:43</th>\n",
       "  </tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fit_one_cycle(2,1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tok = SpacyTokenizer('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Description: \n",
      "arsenius skill capital urgent requirement corporate salespositionnbspcorporate salesdesignationassistant managermanagersr managercompensation lac lac palocationmumbaijob rolenbspthis job profile requires candidate build strong client relation manage overall functionality improve corporate sale amp operation profile requires customer centric professional acquire new account manage end end travel planning corporatenbspcandidate profilegraduates mba preferable tourism year minimum experience given role handling corporate marketing sale candidate handling corporate marketing sale telecom finance retail also considerednbspjob responsibilitiesinterested candidate may share call kind regardsangee nandi arsenius skill capital sale marketing sale corporate sale business development business business sale sale channel sale\n",
      "\n",
      "Class: Sales\n"
     ]
    }
   ],
   "source": [
    "# get single pred\n",
    "description = data.description.values[30]\n",
    "#description = input()\n",
    "tokens = [md.train_dl.vocab.stoi[w] for w in tokenizer.process_text(description, tok)]\n",
    "pred = to_np(F.log_softmax(model(torch.LongTensor(tokens).view(1, -1).cuda()), dim=1).max(1)[1])\n",
    "\n",
    "print(f'Description: \\n{description}\\n\\nClass: {lbl_en.inverse_transform(pred)[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results Summary:**\n",
    "_Provide a brief summary of results obtained like model accuracy & other insights based on EDA & your interpretations_\n",
    "\n",
    "1. Model Accuracy is ~ 52%.\n",
    "2. The DataSet is very imbalanced, oversampig of minority classes may be helpful, or generation using knn.\n",
    "3. Other fields like skill, location, etc.,may be extarcted from the job description which may be helpful in the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
